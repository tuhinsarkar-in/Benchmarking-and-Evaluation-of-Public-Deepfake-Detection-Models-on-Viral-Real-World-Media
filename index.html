<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Main Step: Edit below title -->
    <title>Benchmarking and Cross-Platform Evaluation of Public Deepfake Detection Models on Viral Real-World Media</title>


  <!-- SEO Meta Tags -->
  <meta name="description" content="Benchmarking and cross-platform evaluation of public deepfake detection models on viral real-world media. This academic research page summarizes methodology, results, and key findings from a study testing the reliability of AI deepfake detectors on viral videos." />
  <meta name="keywords" content="deepfake detection, cross-platform evaluation, AI research, academic research, viral media, benchmarking, scientific study, machine learning, misinformation, video forensics, research paper, open dataset, reproducibility, peer-reviewed, publication" />
  <meta name="author" content="Tuhin Sarkar" />
  <meta name="robots" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1" />
  <link rel="canonical" href="https://tuhinsarkar.in/deepfake-benchmark" />

  <!-- Open Graph Meta Tags (for social sharing) -->
  <meta property="og:title" content="Benchmarking Deepfake Detection Models on Viral Media – Academic Study" />
  <meta property="og:description" content="Academic benchmarking and cross-platform evaluation of public deepfake detection models on viral real-world media. Includes methodology, results, and open dataset." />
  <meta property="og:image" content="https://tuhinsarkar.in/assets/og-image.png" />
  <meta property="og:url" content="https://tuhinsarkar.in/deepfake-benchmark" />
  <meta property="og:type" content="article" />
  <meta property="og:site_name" content="Tuhin Sarkar Research" />

  <!-- Twitter Meta Tags -->
  <meta name="twitter:title" content="Benchmarking Deepfake Detection Models on Viral Media – Academic Study" />
  <meta name="twitter:description" content="Academic benchmarking and cross-platform evaluation of public deepfake detection models on viral real-world media. Includes methodology, results, and open dataset." />
  <meta name="twitter:image" content="https://tuhinsarkar.in/assets/og-image.png" />
  <meta name="twitter:card" content="summary_large_image" />

    <!-- Open Graph Meta Tags (For Social Media Sharing) -->
    <!-- <meta
      property="og:title"
      content="Research Papers - Explore Cutting-Edge Research"
    />
    <meta
      property="og:description"
      content=""
    />
    <meta property="og:image" content="path-to-your-image.jpg" />
    <meta property="og:url" content="https://www.yourwebsite.com" />
    <meta property="og:type" content="website" />
    <meta property="og:site_name" content="Research Paper Platform" /> -->

    <!-- Twitter Meta Tags (For Twitter Sharing) -->
    <!-- <meta
      name="twitter:title"
      content="Research Papers - Explore Cutting-Edge Research"
    />
    <meta
      name="twitter:description"
      content=""
    />
    <meta name="twitter:image" content="path-to-your-image.jpg" />
    <meta name="twitter:card" content="summary_large_image" /> -->

    <!-- Canonical Link -->
    <!-- <link rel="canonical" href="https://www.yourwebsite.com" /> -->

    <!-- Favicon for different platforms -->
  

    <!-- Google Fonts -->


    <link href="font.css" rel="stylesheet">
    
    <link rel="stylesheet" type="text/css" href="style.css" />
  </head>
  <body>
 <nav class="nav">
      <div class="nav-container">
        <div class="nav-brand">
          <div class="nav-logo">
            <svg width="32" height="32" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
              <path d="M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 18.477 5.754 18 7.5 18s3.332.477 4.5 1.253m0-13C13.168 5.477 14.754 5 16.5 5c1.747 0 3.332.477 4.5 1.253v13C19.832 18.477 18.247 18 16.5 18c-1.746 0-3.332.477-4.5 1.253" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"/>
            </svg>
            <span class="nav-title">Benchmarking and Cross-Platform Evaluation of Public Deepfake Detection Models on Viral Real-World Media
</span>
          </div>
        </div>
        
  
        
        <div class="nav-controls">
          <button class="theme-toggle-btn" onclick="toggleDarkMode()" aria-label="Toggle theme">
            <svg class="sun-icon" width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
              <circle cx="12" cy="12" r="4" stroke="currentColor" stroke-width="1.5"/>
              <path d="m12 2 0 2m0 16 0 2M4.93 4.93l1.41 1.41m11.32 11.32 1.41 1.41M2 12l2 0m16 0 2 0M4.93 19.07l1.41-1.41M17.66 6.34l1.41-1.41" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"/>
            </svg>
            <svg class="moon-icon" width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
              <path d="M12 3a6 6 0 0 0 9 9 9 9 0 1 1-9-9Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"/>
            </svg>
          </button>
          
          <button class="mobile-menu-btn" aria-label="Toggle mobile menu">
            <span class="hamburger-line"></span>
            <span class="hamburger-line"></span>
            <span class="hamburger-line"></span>
          </button>
        </div>
      </div>
      
     
    </nav>

    <!-- Step 1 Start: Header Part -->

    <!-- 
    Remove if not applicable
    Edit below todo text
    Add URL link by removing # for each authers. Link can be GitHub, LinkedIn, Google Schooler, Website or other
    -->

    <div class="header">
      <h1 class="animate-fade-in animate-delay-1">Benchmarking and Cross-Platform Evaluation of Public Deepfake Detection Models on Viral Real-World Media</h1>
      <div class="authors">
        <p>
          <a href="https://tuhinsarkar.in">Tuhin Sarkar</a><sup>1</sup>,
       
        </p>
        <p>
          <sup>1</sup>Glentree Academy, Bengaluru, Karnataka, India &nbsp;&nbsp; 
      
        </p>
        <p>
          <strong>Student Authors:</strong> Tuhin Sarkar, High School
        </p>
        <p>
          <strong>Keywords:</strong> Deepfakes, Detection, Benchmarking, Accuracy, Misinformation
        </p>
      </div>
      <div style="display: flex; justify-content: center; margin: 28px 0 0 0;">
        <a href="https://doi.org/10.5281/zenodo.17250129" class="open-paper-btn" style="display: inline-flex; align-items: center; gap: 10px; background: linear-gradient(90deg, #007bff 0%, #00c6ff 100%); color: #fff; font-weight: 600; font-size: 1.15em; padding: 14px 32px; border-radius: 32px; box-shadow: 0 4px 16px #007bff22; text-decoration: none; transition: background 0.2s, box-shadow 0.2s; letter-spacing: 0.02em;">
          <svg width="24" height="24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="vertical-align: middle;"><path d="M12 5v14m0 0l-6-6m6 6l6-6"/></svg>
          Open Paper
        </a>
      </div>
          <div style="display: flex; justify-content: center; margin: 28px 0 0 0;">
        <a href="https://doi.org/10.5281/zenodo.17208948" class="open-paper-btn" style="display: inline-flex; align-items: center; gap: 10px; background: linear-gradient(90deg, #007bff 0%, #00c6ff 100%); color: #fff; font-weight: 600; font-size: 1.15em; padding: 14px 32px; border-radius: 32px; box-shadow: 0 4px 16px #007bff22; text-decoration: none; transition: background 0.2s, box-shadow 0.2s; letter-spacing: 0.02em;">
          <svg width="24" height="24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="vertical-align: middle;"><path d="M12 5v14m0 0l-6-6m6 6l6-6"/></svg>
          Open Dataset
        </a>
      </div>
    </div>

    <!-- Step 1 End: Header Part -->
    <!-- Step 2 Start: Button for links -->

    <!-- 
    Add URL links for each buttons according to name mentioned
    Remove # and add the link
    Add new button link if required
    Remove this step if not applicable
    -->

  <div class="buttons">
  <a href="#introduction" class="hover-magnetic pulse-glow">Paper</a>
  <a href="#infographic" class="hover-magnetic">Videos</a>
  <a href="#supplementary" class="hover-magnetic">Code</a>
  <a href="#replicability" class="hover-magnetic">Dataset</a>
  <a href="#supplementary" class="hover-magnetic">Model</a>
  <a href="#bibtex" class="hover-magnetic">BibTex</a>
    </div>

    <!-- Step 2 End: Button for links -->

    <!-- ===== LAYMAN'S TERMS FIRST ===== -->
    
    <!-- TL;DR Section -->
    <div class="tldr-section" id="tldr">
      <h2>
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 8px;">
          <path d="M12 2L3.09 8.26L12 14L20.91 8.26L12 2Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
          <path d="M3.09 15.74L12 22L20.91 15.74" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
          <path d="M3.09 8.26L12 14.52L20.91 8.26" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
        </svg>
        TL;DR (Layman's Summary)
      </h2>
      <div class="horizontal-card-grid">
  <div class="tldr-highlight">
          <h3>
           🔎
            What we did:
          </h3>
          <p>We tested whether popular AI tools that claim to detect deepfakes actually work on real viral videos. To do this, we collected 20 clips that had spread online — 10 confirmed deepfakes and 10 real videos of politicians and celebrities. Then, we ran all of them through two different publicly available deepfake detectors (Deepware AI and UB’s DeepFake-O-Meter), compared their results, and measured how often they got it right or wrong.</p>
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
        </div>
  <div class="tldr-highlight">
          <h3>
           
            Why it matters:
          </h3>
          <p>We tested two popular deepfake detection tools on 20 viral videos (half real, half fake) featuring politicians and celebrities. We wanted to see if these tools could reliably tell the difference between genuine videos and deepfakes that had already fooled millions of people online. To do this, we compared their results side by side, looked at how consistent the detectors were, and checked whether they missed obvious fakes or wrongly flagged real clips.</p>
        </div>
  <div class="tldr-highlight">
          <h3>
           
           📂 Key finding:
          </h3>
          <p>The detectors often got it wrong. Sometimes they flagged real videos as fake, and other times they missed obvious deepfakes that had already gone viral. In short, the tools weren’t reliable enough to trust as a safety net against misinformation.</p>
        </div>
      </div>
      <div class="tldr-stats">
        <div class="stat-item">
          <span class="stat-number">20-60%</span>
          <span class="stat-label">Detection Rate</span>
        </div>
        <div class="stat-item">
          <span class="stat-number">2</span>
          <span class="stat-label">Platforms</span>
        </div>
        <div class="stat-item">
          <span class="stat-number">20</span>
          <span class="stat-label">Viral Videos</span>
        </div>
      </div>
    </div>

    <!-- Impact & Applications Section -->
    <div class="content-section" id="impact">
      <h2>
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 8px;">
          <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"/>
          <path d="M8 14s1.5 2 4 2 4-2 4-2" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
          <path d="M9 9h.01M15 9h.01" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
        </svg>
        Impact & Applications
      </h2>
      <div class="impact-grid">
        <div class="impact-card">
          <div class="impact-icon">
           🗳️
          </div>
          <h3>Election Security</h3>
          <p>Protecting democratic processes by identifying fake political content before it can influence voters and spread misinformation during critical election periods.</p>
        </div>
        <div class="impact-card">
          <div class="impact-icon">
           
           📻
          </div>
          <h3>Media & Journalism</h3>
          <p>Helping news organizations and social media platforms quickly verify the authenticity of viral content to prevent the spread of fabricated news.</p>
        </div>
        <div class="impact-card">
          <div class="impact-icon">
          
        ⚖
          </div>
          <h3>Legal Evidence</h3>
          <p>Supporting legal proceedings by providing systematic evaluation methods for video evidence authenticity in courts and investigations.</p>
        </div>
        <div class="impact-card">
          <div class="impact-icon">
            <svg width="48" height="48" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
              <path d="M12 22s8-4 8-10V5l-8-3-8 3v7c0 6 8 10 8 10z" stroke="currentColor" stroke-width="2"/>
              <path d="M9 12l2 2 4-4" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
          🛡
          </div>
          <h3>Digital Safety</h3>
          <p>Protecting individuals from deepfake harassment and identity theft by improving detection systems on social platforms and messaging apps.</p>
        </div>
      </div>
      
      <div class="split-content">
        <div class="left-panel">
          <h3>
            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 6px;">
              <path d="M21 12a9 9 0 11-6.219-8.56" stroke="currentColor" stroke-width="2"/>
            </svg>
            Current Challenges
          </h3>
          <ul>
            <li><strong>High False Negative Rates:</strong> Current tools miss 40-80% of real deepfakes</li>
            <li><strong>Platform Inconsistency:</strong> Different tools give conflicting results on same content</li>
            <li><strong>Cultural Bias:</strong> Performance varies across different demographic groups</li>
            <li><strong>Technical Limitations:</strong> Resolution and compression affect detection accuracy</li>
          </ul>
              <svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
        
        <div class="right-panel">
          <h3>
           ⚡
            Future Directions
          </h3>
          <ul>
            <li><strong>Consensus Algorithms:</strong> Develop multi-platform agreement systems</li>
            <li><strong>Diverse Training:</strong> Include culturally representative datasets</li>
            <li><strong>Standardized Benchmarks:</strong> Create real-world evaluation standards</li>
            <li><strong>Human-AI Collaboration:</strong> Integrate expert review with automated detection</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- Demo Video Section -->
    <div class="video-section">
      <h2>🎥 Research Demo</h2>
      <div class="video-container">
        <iframe
          width="560"
          height="315"
          src="https://www.youtube.com/embed/ysFav0b472w?si=Rxxp3R6_tkBXAEmP"
          title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          referrerpolicy="strict-origin-when-cross-origin"
          allowfullscreen
        ></iframe>
      </div>
      <p>
        TODO: Brief explanation of what viewers will see in the demo video and its key highlights.
      </p>
    </div>

    <!-- Infographic Section -->
    <div class="content-section" id="infographic">
      <h2>📊 Research Infographic</h2>
      <div class="infographic-container">
        <div class="infographic-placeholder">
          <div class="infographic-icon">🎨</div>
          <h3>Visual Summary</h3>
          <div class="infographic-figures" style="display: flex; flex-direction: column; gap: 32px; margin-top: 16px;">
            <figure style="margin: 0;">
              <img src="figures/conf_matrix_A.png" alt="Figure 1A: Confusion matrix Mapping A" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px #0001;" loading="eager" fetchpriority="high" decoding="async" srcset="figures/conf_matrix_A.png 800w, figures/conf_matrix_A.png 400w" sizes="(max-width: 600px) 100vw, 50vw">
              <figcaption><strong>Figure 1A.</strong> Confusion matrix for Mapping A treating “Suspicious” as positive. Heatmap showing true positives (6), false negatives (4), true negatives (10), and false positives (0) for Deepware AI outputs on 20 viral videos. Accuracy = 80%, sensitivity = 60%, specificity = 100%, precision = 100%.</figcaption>
            </figure>
            <figure style="margin: 0;">
              <img src="figures/conf_matrix_B.png" alt="Figure 1B: Confusion matrix Mapping B" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px #0001;" loading="lazy" decoding="async" srcset="figures/conf_matrix_B.png 800w, figures/conf_matrix_B.png 400w" sizes="(max-width: 600px) 100vw, 50vw">
              <figcaption><strong>Figure 1B.</strong> Confusion matrix for Mapping B treating “Suspicious” as negative. Heatmap showing true positives (2), false negatives (8), true negatives (10), and false positives (0) for Deepware AI outputs. Accuracy = 60%, sensitivity = 20%, specificity = 100%, precision = 100%.</figcaption>
            </figure>
            <figure style="margin: 0;">
              <img src="figures/per_video_detection_scores.png" alt="Figure 2: Per-video detection scores" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px #0001;" loading="lazy" decoding="async" srcset="figures/per_video_detection_scores.png 800w, figures/per_video_detection_scores.png 400w" sizes="(max-width: 600px) 100vw, 50vw">
              <figcaption><strong>Figure 2.</strong> Per-video detection scores for 10 deepfake samples. Grouped bar graph comparing Deepware AI ensemble scores (blue) and UB DeepFake-O-Meter mean detector scores (red). Highlights large variance across videos such as Biden, Trump, and Rashmika Mandanna.</figcaption>
            </figure>
            <figure style="margin: 0;">
              <img src="figures/cross_platform_agreement.png" alt="Figure 3: Cross-platform agreement" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px #0001;" loading="lazy" decoding="async" srcset="figures/cross_platform_agreement.png 800w, figures/cross_platform_agreement.png 400w" sizes="(max-width: 600px) 100vw, 50vw">
              <figcaption><strong>Figure 3.</strong> Cross-platform agreement on deepfake detection. Scatter plot comparing Deepware AI ensemble scores (x-axis) to UB DeepFake-O-Meter mean scores (y-axis). Each point represents a video sample; labels identify subjects. Wide scatter indicates inconsistent cross-platform agreement.</figcaption>
            </figure>
            <figure style="margin: 0;">
              <img src="figures/score_distribution_by_type.png" alt="Figure 4: Score distribution by manipulation type" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px #0001;" loading="lazy" decoding="async" srcset="figures/score_distribution_by_type.png 800w, figures/score_distribution_by_type.png 400w" sizes="(max-width: 600px) 100vw, 50vw">
              <figcaption><strong>Figure 4.</strong> Score distribution by manipulation type. Boxplot comparing detection scores for face-swap/identity-replacement deepfakes vs lip-synthesis/dubbing manipulations. Face-swap examples (e.g., Obama, Morgan Freeman) show higher median detection likelihoods.</figcaption>
            </figure>
          </div>
        </div>
      </div>
    </div>

    <!-- ===== TECHNICAL / ACADEMIC CONTENT ===== -->
    
    <!-- Abstract Section -->
  <div class="content-section" id="introduction">
      <h2>📄 Abstract</h2>
      <p>Deepfakes pose serious risks to public trust and information integrity; we tested whether publicly available detection tools reliably identify viral real-world deepfakes. We hypothesized that off-the-shelf detectors would show inconsistent accuracy and produce both false positives and false negatives when applied to in-the-wild videos. To test this, we evaluated 20 viral clips (10 confirmed deepfakes, 10 authentic controls) using two public detection platforms and recorded ensemble and per-model likelihoods across more than ten detectors. Results revealed substantial cross-platform disagreement: one platform's ensemble flagged only a minority of confirmed deepfakes while the research platform produced extreme per-model score variance, so that sensitivity depended strongly on how an intermediate "Suspicious" label was treated. Depending on the binary mapping used, measured sensitivity varied widely while specificity remained high for this sample. We conclude that current public detectors provide useful signals but are not yet reliable as sole arbiters of authenticity for viral content; we recommend publishing full per-video numeric outputs, versioned model identifiers, and pairing automated screening with human expert review.</p>
    </div>

    <!-- Step 4 Start: Add your paper introduction -->

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    -->

  <!-- Removed duplicate Introduction Section -->

    <!-- Step 4 End: Add your paper introduction -->

    <!-- Step 5 Start: Add your paper methodology -->

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    -->

  <div class="content-section sidebar-layout" id="methodology">
      <div class="main-content">
        <h2>
          <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 8px;">
            <path d="M14.7 6.3a1 1 0 000 1.4l1.6 1.6a1 1 0 001.4 0l3.77-3.77a6 6 0 01-7.94 7.94l-6.91 6.91a2.12 2.12 0 01-3-3l6.91-6.91a6 6 0 017.94-7.94l-3.76 3.76z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
          </svg>
          Methodology
        </h2>
      
      <h3>
        <svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 6px;">
          <path d="M23 7l-7 5 7 5V7z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
          <rect x="1" y="5" width="15" height="14" rx="2" ry="2" stroke="currentColor" stroke-width="2"/>
        </svg>
        Video Sample Selection
      </h3>
      <p>We compiled a convenience sample of <strong>20 viral videos</strong>: 10 confirmed deepfakes and 10 authentic control videos featuring prominent political and entertainment figures. Deepfake items were drawn from documented repositories, academic demonstrations, BBC News segments, and viral media that had been publicly debunked by fact-checking organizations.</p>
  <p style="margin-top: 10px; padding: 10px 16px; border-radius: 6px; font-size: 1em;">
        <strong>For full transparency:</strong> The exact titles and descriptions of all <b>Deepfake</b> and <b>Authentic</b> video samples used in this study are listed in the <a href="#video-samples" style="color: #007bff; text-decoration: underline;">Video Sample Collection & Dataset</a> section below. Each sample is available for download, and the lists match the dataset files used for all analyses. Please refer to these lists for precise sample documentation and replication.
      </p>
      
      <h4>
        👥
        Notable Test Cases Include:
      </h4>
      <ul>
        <li><strong>Political Figures:</strong> Barack Obama BBC News demonstration, Joe Biden's "pistachio story", Donald Trump LipSynthesis, Amit Shah reservation video</li>
        <li><strong>Celebrities:</strong> Morgan Freeman Singularity video, Anderson Cooper LipSynthesis, Bill Gates deepfake examples</li>
        <li><strong>Indian Entertainment:</strong> Aamir Khan & Ranveer Singh political endorsements, Rashmika Mandanna viral video</li>
        <li><strong>Technical Specifications:</strong> File sizes 5.7-34.4 MB, durations 48-242 seconds, resolutions 480×360 to 3840×2160 pixels</li>
      </ul>
      
        <h3>
          <svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 6px;">
            <circle cx="11" cy="11" r="8" stroke="currentColor" stroke-width="2"/>
            <path d="m21 21-4.35-4.35" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
          </svg>
          Detection Platforms
        </h3>
        <p>We employed two publicly available detection platforms:</p>
        
        <div class="platform-comparison">
          <div class="platform-card">
            <h4>Platform 1: Deepware AI Scanner (Beta)</h4>
            <ul>
              <li><strong>Ensemble Architecture:</strong> Three component detectors with categorical thresholds:
                <ul>
                  <li>Deepfake Detected (>80%)</li>
                  <li>Suspicious (50-80%)</li>
                  <li>No Deepfake Detected (<50%)</li>
                </ul>
              </li>
              <li><strong>Components:</strong> Avatarify, proprietary Deepware model, Seferbekov</li>
              <li><strong>Testing Period:</strong> April 2024 - September 2025</li>
            </ul>
          </div>
          
          <div class="platform-card">
            <h4>Platform 2: UB Media Forensics Lab's DeepFake-O-Meter</h4>
            <ul>
              <li><strong>11 State-of-the-Art Models (2019-2025):</strong>
                <ul>
                  <li><strong>Modern Models:</strong> AVSRDD (2025), LIPINC (2024), CFM (2025)</li>
                  <li><strong>Established Models:</strong> AVAD (2023), AltFreezing (2023), LSDA (2024)</li>
                  <li><strong>Traditional Models:</strong> DSP-FWA (2019), FTCN (2021), SBI (2022)</li>
                  <li><strong>Specialized Models:</strong> TALL (2023), WAV2LIP-STA (2022), XCLIP (2022)</li>
                </ul>
              </li>
              <li><strong>Research Interface:</strong> Academic settings with detailed per-model likelihood scores</li>
            </ul>
          </div>
        </div>
      </div>
      
      <div class="sidebar-content">
        <div class="methodology-steps">
          <div class="methodology-step" data-step="1">
            <h4>⚙️ Evaluation Approach</h4>
            <p>For each video, we recorded:</p>
            <ul>
              <li>Ground-truth classification (Deepfake vs Authentic)</li>
              <li>Platform ensemble scores and categorical labels</li>
              <li>Individual component/model scores</li>
              <li>Technical metadata (resolution, duration, encoding)</li>
              <li>Scan timestamps and any analyst notes</li>
            </ul>
          </div>
          
          <div class="methodology-step" data-step="2">
            <h4>📊 Binary Classification Mappings</h4>
            <p>Since Deepware returns three-level categorical output, we evaluated two operational mappings:</p>
            <ul>
              <li><strong>Mapping A (Lenient)</strong>: Treat "Suspicious" as positive detection</li>
              <li><strong>Mapping B (Conservative)</strong>: Only "Deepfake Detected" counts as positive</li>
            </ul>
          </div>
          
          <div class="methodology-step" data-step="3">
            <h4>📏 Performance Metrics</h4>
            <p>We computed standard binary classification metrics: accuracy, sensitivity (recall), specificity, precision, and F1 score using confusion matrices derived from categorical counts.</p>
          </div>
        </div>
      </div>
    </div>

    <!-- Step 5 End: Add your paper methodology -->

    <!-- Step 6 Start: Add your paper results -->

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    Below have pre-build code for:
    -> 3 Images Carousel
    -> 3 Videos Carousel
    -> Single YouTube Video
    -> YouTube Video List
    If you do not need those, remove them.
    How to add YouTube Video:
    -> Go to the video page
    -> Click Share Button and Click <> Mark
    -> This will give <iframe></iframe> tag code
    -> Replace below <iframe></iframe> tag with your code
    -->

  <div class="content-section" id="results">
      <h2>
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 8px;">
          <path d="M3 3v18h18" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
          <path d="M18.7 8l-5.1 5.2-2.8-2.7L7 14.3" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
        </svg>
        Results
      </h2>
      
      <!-- Key Performance Metrics -->
      <div class="metrics-grid">
        <div class="metric-card">
          <span class="metric-value">20%</span>
          <span class="metric-label">Deepfake Detection Rate (Deepware)</span>
        </div>
        <div class="metric-card">
          <span class="metric-value">40%</span>
          <span class="metric-label">Suspicious Classifications</span>
        </div>
        <div class="metric-card">
          <span class="metric-value">98.6%</span>
          <span class="metric-label">Max Score Variance (Cross-Platform)</span>
        </div>
        <div class="metric-card">
          <span class="metric-value">8/10</span>
          <span class="metric-label">AVSRDD Detection Success</span>
        </div>
        <div class="metric-card">
          <span class="metric-value">0%</span>
          <span class="metric-label">False Positives (Authentic Videos)</span>
        </div>
        <div class="metric-card">
          <span class="metric-value">11</span>
          <span class="metric-label">AI Models Tested</span>
        </div>
      </div>
      
      <h3>
        <svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 6px;">
          <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"/>
          <circle cx="12" cy="12" r="6" stroke="currentColor" stroke-width="2"/>
          <circle cx="12" cy="12" r="2" stroke="currentColor" stroke-width="2"/>
        </svg>
        Key Findings
      </h3>
      <p>Our analysis revealed significant limitations and inconsistencies in current public deepfake detection tools when applied to viral real-world content:</p>
      
      <div class="results-grid">
        <!-- Deepfake and Real Sample Analysis (Expanded) -->
        <div class="result-card">
          <h3>Benchmarking and Cross-Platform Evaluation of Public Deepfake Detection Models on Viral Real-World Media</h3>
          <h4>Raw Data Results</h4>
          <h4>Sample Fake Deepfake Clips used for testing:</h4>
          <ol>
            <li>Viral Deepfake Videos Thrive Of Aamir Khan & Ranveer Singh Endorsing Political Parties – Business today</li>
            <li>Amit Shah Fake Video: Debunking the Fake Video of Amit Shah On Reservations – The Indian Express</li>
            <li>AI Deepfake Video Of Actress Rashmika Mandanna Going Viral – Business Today</li>
            <li>Anderson Cooper, 4K Original/(Deep) Fake Example - LipSynthesis</li>
            <li>Fake Obama created using AI video tool - BBC News</li>
            <li>This is not Morgan Freeman - A Deepfake Singularity</li>
            <li>President Joe Biden's Magical Pistachio Story (Deepfake AI)</li>
            <li>Deepfake example. Original/Deepfake close shot Bill Gates.</li>
            <li>2024 Deepfake Example in 4k - ORIGINAL/DEEPFAKE - Bill Gates</li>
            <li>Trump 4k Deepfake example – LipSynthesis</li>
          </ol>
          <h4>Sample Real Deepfake Clips used for testing:</h4>
          <ol>
            <li>Aamir Khan-Reena की लव स्टोरी कैसे शुरू हुई, घरवालों ने क्या हंगामा किया, छुपकर शादी क्यों करनी पड़ी.mp4</li>
            <li>Anderson Cooper’s tribute to his friend Anthony Bourdain.mp4</li>
            <li>Highlights from Obama's farewell address.mp4</li>
            <li>HM Amit Shah’s Fiery Remark in Parliament_ ‘Hindu Terrorist Nahi Ho Sakta’ _ Amit Shah _ Rajya Sabha.mp4</li>
            <li>Morgan Freeman Re-Enacts The Shawshank Redemption _ The Graham Norton Show.mp4</li>
            <li>President Joe Biden Takes the Oath of Office _ Biden-Harris Inauguration 2021.mp4</li>
            <li>President Trump's Inaugural Address.mp4</li>
            <li>Ranveer Singh On Playing Khilji In Padmaavat _ India Today Exclusive Interview.mp4</li>
            <li>Rashmika Mandanna Interview with Anupama Chopra _ Mission Majnu _ Goodbye _ Film Companion.mp4</li>
            <li>The next outbreak_ We’re not ready _ Bill Gates _ TED.mp4</li>
          </ol>
          <h4>Tool 1: Deepware A.I.</h4>
          <p><strong>All Fake Video Results:</strong></p>
          <ul>
            <li>The video titled “Viral Deepfake Videos Thrive Of Aamir Khan & Ranveer Singh Endorsing Political Parties – Business Today”, was scanned on 2025-09-20 at 06:19:29 UTC. The scan result indicates <b>SUSPICIOUS</b>. Model results: Avatarify 39% (no deepfake), Deepware 25% (no deepfake), Seferbekov 75% (suspicious), Ensemble 55% (suspicious). Duration: 181s, 1280x720, 29.97fps, h264; audio: 181s, stereo, 48kHz, AAC.</li>
            <li>The video titled “Amit Shah Fake Video: Debunking the Fake Video of Amit Shah On Reservations – The Indian Express”, scanned 2025-09-20 at 06:25:41 UTC. <b>SUSPICIOUS</b>. Model results: Avatarify 0%, Deepware 20%, Seferbekov 97% (deepfake), Ensemble 67% (suspicious). Duration: 162s, 1280x720, 30fps, h264; audio: 162s, stereo, 48kHz, AAC.</li>
            <li>The video titled “AI Deepfake Video Of Actress Rashmika Mandanna Going Viral – Business Today”, scanned 2025-09-20 at 06:28:12 UTC. <b>NO DEEPFAKE DETECTED</b>. Model results: Avatarify 24%, Deepware 16%, Seferbekov 46%, Ensemble 28%. Duration: 172s, 1280x720, 29.97fps, h264; audio: 172s, stereo, 48kHz, AAC.</li>
            <li>The video titled “Anderson Cooper, 4K Original/(Deep) Fake Example - LipSynthesis”, scanned 2025-09-20 at 06:31:05 UTC. <b>SUSPICIOUS</b>. Model results: Avatarify 72% (suspicious), Deepware 0%, Seferbekov 3%, Ensemble 0%. Duration: 210s, 3840x2160, 30fps, h264; audio: 210s, stereo, 48kHz, AAC.</li>
            <li>The video titled “Fake Obama created using AI video tool - BBC News”, scanned 2025-09-20 at 06:34:42 UTC. <b>DEEPFAKE DETECTED</b>. Model results: Analyst confirmed deepfake, Avatarify 19%, Deepware 0%, Seferbekov 49%, Ensemble 12%. Duration: 200s, 1920x1080, 29.97fps, h264; audio: 200s, stereo, 48kHz, AAC.</li>
            <li>The video titled “This is not Morgan Freeman - A Deepfake Singularity”, scanned 2025-09-20 at 06:37:10 UTC. <b>DEEPFAKE DETECTED</b>. Model results: Analyst deepfake detected, Avatarify 18%, Deepware 0%, Seferbekov 0%, Ensemble 0%. Duration: 198s, 1920x1080, 29.97fps, h264; audio: 198s, stereo, 48kHz, AAC.</li>
            <li>The video titled “President Joe Biden's Magical Pistachio Story (Deepfake AI)”, scanned 2025-09-20 at 06:39:55 UTC. <b>SUSPICIOUS</b>. Model results: Avatarify 29%, Deepware 34%, Seferbekov 71% (suspicious), Ensemble 58% (suspicious). Duration: 185s, 1280x720, 29.97fps, h264; audio: 185s, stereo, 48kHz, AAC.</li>
            <li>The video titled “Deepfake example. Original/Deepfake close shot Bill Gates.”, scanned 2025-09-20 at 06:42:12 UTC. <b>NO DEEPFAKE DETECTED</b>. Model results: Avatarify 20%, Deepware 0%, Seferbekov 2%, Ensemble 0%. Duration: 180s, 1280x720, 29.97fps, h264; audio: 180s, stereo, 48kHz, AAC.</li>
            <li>The video titled “2024 Deepfake Example in 4k - ORIGINAL/DEEPFAKE - Bill Gates”, scanned 2025-09-20 at 06:45:00 UTC. <b>NO DEEPFAKE DETECTED</b>. Model results: Avatarify 20%, Deepware 0%, Seferbekov 2%, Ensemble 0%. Duration: 182s, 3840x2160, 30fps, h264; audio: 182s, stereo, 48kHz, AAC.</li>
            <li>The video titled “Trump 4k Deepfake example – LipSynthesis”, scanned 2025-09-20 at 06:48:33 UTC. <b>NO DEEPFAKE DETECTED</b>. Model results: Avatarify 40%, Deepware 2%, Seferbekov 1%, Ensemble 1%. Duration: 190s, 3840x2160, 30fps, h264; audio: 190s, stereo, 48kHz, AAC.</li>
          </ul>
          <p><strong>All Real Video Results:</strong></p>
          <ul>
            <li>All real videos scanned in September 2025. Deepware A.I. is in Beta; results are advisory only.</li>
            <li>All real videos (see list above) were marked as <b>NO DEEPFAKE DETECTED</b> by all models (Avatarify, Deepware, Seferbekov, Ensemble), with low probabilities (0-35%). Video/audio specs varied; see supplementary for details.</li>
          </ul>
          <h4>Tool 2: Deepfake-O-Meter UB Media Forensics Lab</h4>
          <p>This project is supported by the University at Buffalo and the National Science Foundation (SaTC-2153112). The tool aggregates many advanced models for deepfake detection. See below for model list and results.</p>
          <details>
            <summary><b>Detection Models Used</b></summary>
            <ul>
              <li>AVAD (2023): Audio-visual anomaly detection. <a href="https://github.com/cfeng16/audio-visual-forensics">Code</a></li>
              <li>AVSRDD (2025): Dual-branch audio/visual deepfake detection. <a href="#">ACM DOI</a></li>
              <li>AltFreezing (2023): Alternately freezes spatial/temporal weights. <a href="https://github.com/ZhendongWang6/AltFreezing">Code</a></li>
              <li>CFM (2025): Fine-grained triplet relation learning. <a href="https://github.com/LoveSiameseCat/CFM">Code</a></li>
              <li>DSP-FWA (2019): Affine face warping artifacts. <a href="https://github.com/yuezunli/DSP-FWA">Code</a></li>
              <li>FTCN (2021): Temporal convolutional network. <a href="https://github.com/yinglinzheng/FTCN">Code</a></li>
              <li>LIPINC (2024): Lip-sync forgery detection. </li>
              <li>LSDA (2024): Synthesized video/image detection.</li>
              <li>SBI (2022): Self-blended images. <a href="https://github.com/mapooon/SelfBlendedImages">Code</a></li>
              <li>TALL (2023): Temporal-aware deepfake detector. <a href="https://github.com/rainy-xu/TALL4Deepfake">Code</a></li>
              <li>WAV2LIP-STA (2022): Wav2Lip-generated deepfake detection. <a href="https://github.com/shanface33/Deepfake_Model_Attribution">Code</a></li>
              <li>XCLIP (2022): Cross-modal pretraining. <a href="https://github.com/microsoft/VideoX/tree/master/X-CLIP">Code</a></li>
            </ul>
          </details>
          <p><strong>All Fake Video Results:</strong></p>
          <ol>
            <li><b>Amit Shah Fake Video</b>: DSP-FWA 96.1%, FTCN 0.4%, WAV2LIP-STA 48.3%, SBI 22.4%, XCLIP 71.4%, AltFreezing 16.7%, TALL 98.8%, LIPINC No Lip Movement, LSDA 74.2%, AVSRDD 99.7%, CFM 38.2%. Second run: similar scores. High likelihood of being fake by most advanced models.</li>
            <li><b>Anderson Cooper.mp4</b>: AVSRDD 99.9%, AltFreezing 85.1%, CFM 22.1%, DSP-FWA 25.2%, FTCN 0.0%, LIPINC 98.3%, LSDA 46.9%, SBI 20.5%, TALL 81.8%, WAV2LIP-STA 8.3%, XCLIP 89.4%. Most advanced models indicate fake.</li>
            <li><b>Bill Gates.mp4</b>: AVSRDD 0.4%, AltFreezing 86.4%, CFM 32.9%, DSP-FWA 38.2%, FTCN 6.4%, LIPINC 99.8%, LSDA 22.3%, SBI 14.2%, TALL 97.5%, WAV2LIP-STA 18.2%, XCLIP 96.2%. Mixed, but several models show high likelihood.</li>
            <li><b>Joe.mp4</b>: AVSRDD 100.0%, AltFreezing 18.3%, CFM 38.3%, DSP-FWA 99.8%, FTCN 0.1%, LIPINC 99.9%, LSDA 30.6%, SBI 14.5%, TALL 100.0%, WAV2LIP-STA 85.3%, XCLIP 100.0%. Strong consensus for fake.</li>
            <li><b>MorganFreeman.mp4</b>: AVSRDD 100.0%, AltFreezing 18.3%, CFM 38.3%, DSP-FWA 99.8%, FTCN 0.1%, LIPINC 99.9%, LSDA 30.6%, SBI 14.5%, TALL 100.0%, WAV2LIP-STA 85.3%, XCLIP 100.0%. Strong consensus for fake.</li>
            <li><b>Obama.mp4</b>: AVSRDD 100.0%, AltFreezing 63.8%, CFM 38.9%, DSP-FWA 84.8%, FTCN 1.4%, LIPINC 100.0%, LSDA 33.2%, SBI 10.2%, TALL 9.0%, WAV2LIP-STA 37.8%, XCLIP 99.1%. Advanced models indicate fake.</li>
            <li><b>Ranveer Singh.mp4</b>: AVSRDD 99.9%, AltFreezing 11.3%, CFM 51.4%, DSP-FWA 97.7%, FTCN 0.9%, LIPINC 100.0%, LSDA 35.6%, SBI 9.0%, TALL 99.7%, WAV2LIP-STA 85.8%, XCLIP 88.5%. Strong consensus for fake.</li>
            <li><b>Rashmika.mp4</b>: AVSRDD 100.0%, AltFreezing 56.8%, CFM 35.7%, DSP-FWA 34.4%, FTCN 7.5%, LIPINC No Lip Movement, LSDA 55.7%, SBI 44.4%, TALL 73.2%, WAV2LIP-STA 36.4%, XCLIP 86.9%. Advanced models indicate fake.</li>
            <li><b>Trump.mp4</b>: AVSRDD 99.6%, DSP-FWA 71.2%, TALL 44.1%, XCLIP 38.1%, LIPINC 35.6%, AVAD 32.9%, CFM 28.2%, WAV2LIP-STA 25.0%, AltFreezing 0.2%, LSDA 14.8%, SBI 16.1%. Mixed, but several models show high likelihood.</li>
          </ol>
          <p><strong>All Real Video Results:</strong></p>
          <ol>
            <li><b>Aamir Khan-Reena...</b>: AVSRDD 100%, LIPINC 100%, TALL 97.5%, CFM 55.6%, AVAD 42.9%, WAV2LIP-STA 48.1%. AltFreezing 5.6%, FTCN 1.8%, SBI 6.7%, XCLIP 16.0%, LSDA 26.3%, DSP-FWA 19.6%. Advanced models indicate fake, older models do not.</li>
            <li><b>Anderson Cooper’s tribute...</b>: AVSRDD 100%, LIPINC 100%, TALL 56.8%, AVAD 47.6%, CFM 48.5%, XCLIP 49.5%. DSP-FWA 33.5%, LSDA 35.3%, WAV2LIP-STA 26.1%. AltFreezing 2.3%, FTCN 0.0%, SBI 0.3%. Advanced models indicate fake, older models do not.</li>
            <li><b>Highlights from Obama's farewell address.mp4</b>: AVSRDD 100%, LIPINC 98.0%, TALL 94.8%. LSDA 48.5%, CFM 41.1%, WAV2LIP-STA 37.4%, XCLIP 33.0%, AVAD 31.1%, SBI 26.7%. AltFreezing 3.0%, DSP-FWA 0.1%, FTCN 0.1%. Advanced models indicate fake, older models do not.</li>
            <li><b>HM Amit Shah’s Fiery Remark...</b>: AVSRDD 100%, LIPINC 100%, XCLIP 98.6%, TALL 93.2%, WAV2LIP-STA 93.4%, AltFreezing 66.4%. CFM 48.5%, LSDA 41.9%, SBI 32.9%, AVAD 30.6%. DSP-FWA 2.3%, FTCN 1.9%. Advanced models indicate fake, older models do not.</li>
            <li><b>Morgan Freeman Re-Enacts...</b>: AVSRDD 99.9%, TALL 96.4%, XCLIP 86.5%, LIPINC 83.5%, AltFreezing 88.1%. WAV2LIP-STA 64.2%, CFM 51.2%. DSP-FWA 40.0%, FTCN 34.8%, AVAD 34.6%. LSDA 23.9%, SBI 11.7%. Advanced models indicate fake, older models do not.</li>
            <li><b>President Joe Biden Takes the Oath...</b>: AVSRDD 100%, LIPINC 100%, XCLIP 96.2%. CFM 48.2%, AVAD 33.8%. LSDA 25.4%, WAV2LIP-STA 14.2%, SBI 11.0%, FTCN 8.2%. AltFreezing 3.5%, DSP-FWA 0.0%, TALL 0.6%. Advanced models indicate fake, older models do not.</li>
            <li><b>President Trump's Inaugural Address.mp4</b>: AVSRDD 100%, LIPINC 100%, XCLIP 96.2%. CFM 46.7%, AVAD 33.8%. LSDA 25.4%, WAV2LIP-STA 14.2%, SBI 11.0%, FTCN 8.2%. AltFreezing 3.5%, DSP-FWA 0.0%, TALL 0.6%. Advanced models indicate fake, older models do not.</li>
            <li><b>Rashmika Mandanna Interview...</b>: AVSRDD 99.9%, LIPINC 99.8%, TALL 99.4%, XCLIP 79.0%, WAV2LIP-STA 72.3%. CFM 44.8%, AVAD 36.7%, LSDA 28.3%, DSP-FWA 26.8%. FTCN 0.7%, SBI 4.9%, AltFreezing 6.3%. Advanced models indicate fake, older models do not.</li>
            <li><b>The next outbreak_ We’re not ready _ Bill Gates _ TED.mp4</b>: AVSRDD 100%, TALL 98.8%, XCLIP 98.9%, LIPINC 95.3%. WAV2LIP-STA 50.7%, CFM 42.1%, AVAD 40.0%. LSDA 32.8%, DSP-FWA 21.4%, SBI 15.6%, AltFreezing 9.4%, FTCN 0.4%. Advanced models indicate fake, older models do not.</li>
          </ol>
          <p><em>Note: These percentages reflect statistical correlations with real and fake samples in training datasets and should not be interpreted as definitive evidence of authenticity or fabrication. See supplementary for full per-model breakdowns and references.</em></p>
        </div>
      </div>
      
      <h3>📈 Performance by Content Type</h3>
      <ul>
        <li><strong>Face-swap deepfakes</strong> (Obama, Morgan Freeman) produced higher detection signals than lip-synthesis manipulations</li>
        <li><strong>Political content</strong> showed mixed results with occasional false positives on authentic speeches</li>
        <li><strong>Cultural factors</strong> affected detection - Indian entertainment deepfakes showed inconsistent patterns</li>
        <li><strong>Technical factors</strong> like resolution and compression affected detection consistency</li>
      </ul>
      
      <h3>⚠️ Critical Implications</h3>
      <p><strong>Bottom Line:</strong> Current public detectors provide useful signals but are not reliable enough to serve as sole arbiters of authenticity for viral content. The high specificity (few false alarms) comes at the cost of poor sensitivity (missing many real deepfakes).</p>
      
      <h3>🔬 Technical Factors Affecting Detection</h3>
      <ul>
        <li><strong>Content Type Impact:</strong>
          <ul>
            <li>Face-swap/identity-replacement deepfakes performed better than lip-synthesis</li>
            <li>Political content showed mixed results with occasional false positives on authentic speeches</li>
            <li>Cultural context affected performance (Indian entertainment deepfakes showed inconsistent patterns)</li>
          </ul>
        </li>
        <li><strong>Technical Specifications:</strong>
          <ul>
            <li>Higher resolution content (3840×2160) sometimes reduced detection consistency</li>
            <li>Lower resolution clips (480×360) elicited more consistent flags among advanced models</li>
            <li>Video compression and multi-stage postprocessing masked detector cues</li>
            <li>Platform-specific compression from viral sharing affected artifacts</li>
          </ul>
        </li>
      </ul>
      
      <h3>⚖️ Operational Implications</h3>
      <ul>
        <li><strong>High-Stakes Contexts:</strong> Should NOT be used as sole arbiters for legal evidence, election monitoring, or content takedown decisions</li>
        <li><strong>Recommended Use:</strong> As triage tools flagging material for human expert review</li>
        <li><strong>Transparency Requirements:</strong> Publishers must document thresholds, model versions, analyst interventions, and scan timestamps</li>
        <li><strong>Threshold Sensitivity:</strong> Performance claims meaningless without specifying binary mapping strategy</li>
      </ul>

    </div>

    <!-- Conclusion Section -->
  <div class="content-section" id="conclusion">
      <h2>🎯 Conclusion</h2>
      <p>Our analysis demonstrates that currently accessible detection tools offer useful signals but remain <strong>insufficiently reliable for fully automated judgments</strong> on viral real-world videos. While these tools showed excellent specificity (correctly identifying authentic content), their sensitivity varied dramatically depending on operational thresholds and content characteristics.</p>
      
      <p>The substantial disagreement both within and across platforms points to deeper methodological issues. Current detectors respond to different artifact signatures rather than converging on robust indicators of synthetic origin, leading to situations where identical content produces near-certain and near-zero likelihood scores depending on the model consulted.</p>
      
      <p><strong>Key Recommendations:</strong></p>
      <ul>
        <li>Automated detectors should be used as <strong>triage tools</strong> paired with human expert review, not as sole arbiters</li>
        <li>Transparency about thresholds, model versions, and analyst interventions is essential</li>
        <li>Research should focus on principled ensemble weighting, model calibration, and domain-adaptive training</li>
        <li>Evaluation protocols must reflect the messy, compressed, and culturally varied media found in real-world circulation</li>
      </ul>
      
      <p>Until significant improvements are realized, automated detection should be used cautiously and as part of a broader, human-supervised verification workflow to protect against misinformation while avoiding false accusations.</p>
    </div>

    <!-- Study Limitations & Future Work -->
  <div class="content-section" id="limitations">
      <h2>
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 8px;">
          <path d="M12 9v4m0 4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
        </svg>
        Study Limitations & Future Directions
      </h2>
      
      <h3>
        <svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 6px;">
          <path d="M10.29 3.86L1.82 18a2 2 0 001.71 3h16.94a2 2 0 001.71-3L13.71 3.86a2 2 0 00-3.42 0z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
          <path d="M12 9v4m0 4h.01" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
        </svg>
        Current Study Limitations
      </h3>
      <div class="limitations-content">
        <ul>
          <li><strong>Sample Size:</strong> Limited to 20 high-profile viral clips, which constrains statistical power and may not represent the full diversity of real-world manipulations</li>
          <li><strong>Ground Truth Verification:</strong> Established via public debunking reports and media documentation rather than direct access to generation artifacts</li>
          <li><strong>Temporal Snapshot:</strong> Results reflect detection model capabilities at specific time points (April 2024 - September 2025) since models evolve rapidly</li>
          <li><strong>Cultural/Language Scope:</strong> Focused primarily on English-language and Western/Indian content</li>
          <li><strong>Statistical Approach:</strong> Emphasized descriptive metrics rather than inferential testing due to modest sample size</li>
        </ul>
      </div>
      
      <h3>
        <svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 6px;">
          <path d="M12 2l3.09 6.26L22 9.27l-5 4.87 1.18 6.88L12 17.77l-6.18 3.25L7 14.14 2 9.27l6.91-1.01L12 2z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
        </svg>
        Future Research Directions
      </h3>
      <div class="future-work-expanded">
        <div class="future-category">
          <h4>
            <svg width="18" height="18" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 6px;">
              <path d="M3 3v18h18" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
              <path d="M18.7 8l-5.1 5.2-2.8-2.7L7 14.3" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
            </svg>
            Enhanced Evaluation
          </h4>
          <ul>
            <li>Expand testing to more diverse content (different languages, cultures, generation methods)</li>
            <li>Create standardized benchmarks for real-world deepfake evaluation</li>
            <li>Develop cross-dataset evaluation protocols that capture distributional diversity</li>
          </ul>
        </div>
        
        <div class="future-category">
          <h4>
            <svg width="18" height="18" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 6px;">
              <path d="M12 2L2 7l10 5 10-5-10-5zM2 17l10 5 10-5M2 12l10 5 10-5" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
            </svg>
            Technical Improvements
          </h4>
          <ul>
            <li>Develop better consensus algorithms combining multiple detectors</li>
            <li>Focus on principled ensemble weighting and model calibration</li>
            <li>Implement domain-adaptive training for robustness across content types</li>
            <li>Improve model explainability to help experts interpret detection decisions</li>
          </ul>
        </div>
        
        <div class="future-category">
          <h4>
            <svg width="18" height="18" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 6px;">
              <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z" stroke="currentColor" stroke-width="2"/>
              <circle cx="12" cy="12" r="3" stroke="currentColor" stroke-width="2"/>
            </svg>
            Transparency & Standards
          </h4>
          <ul>
            <li>Establish requirements for publishing raw per-video numeric outputs</li>
            <li>Mandate versioned model identifiers and scan timestamps</li>
            <li>Document all analyst interventions and threshold choices</li>
            <li>Create industry standards for detection platform transparency</li>
          </ul>
        </div>
        
        <div class="future-category">
          <h4>
            <svg width="18" height="18" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 6px;">
              <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"/>
              <path d="M2 12h20M12 2a15.3 15.3 0 014 10 15.3 15.3 0 01-4 10 15.3 15.3 0 01-4-10 15.3 15.3 0 014-10z" stroke="currentColor" stroke-width="2"/>
            </svg>
            Real-World Application
          </h4>
          <ul>
            <li>Integrate human expert review workflows with automated detection</li>
            <li>Develop policies for high-stakes contexts (legal evidence, election monitoring)</li>
            <li>Address compression artifacts and multi-stage sharing effects</li>
            <li>Study demographic and cultural biases in detection systems</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- FAQ Section -->
  <div class="content-section" id="faq">
      <h2>
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 8px;">
          <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"/>
          <path d="M9.09 9a3 3 0 015.83 1c0 2-3 3-3 3" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
          <path d="M12 17h.01" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
        </svg>
        Frequently Asked Questions
      </h2>
      <div class="faq-container">
        <div class="faq-item">
          <button class="faq-question" onclick="toggleFAQ(this)">
            <span>What problem does this research solve?</span>
            <span class="faq-toggle">+</span>
          </button>
          <div class="faq-answer">
            <p>With AI-generated deepfakes spreading rapidly on social media, people need to know if they can trust the online detection tools that claim to identify fake videos. Our research tests whether these popular tools actually work on real viral content, revealing serious limitations that could affect how we combat misinformation.</p>
          </div>
        </div>
        
        <div class="faq-item">
          <button class="faq-question" onclick="toggleFAQ(this)">
            <span>How is this different from existing research?</span>
            <span class="faq-toggle">+</span>
          </button>
          <div class="faq-answer">
            <p>Previous studies only tested detection models on controlled, laboratory-created datasets. We're the first to systematically evaluate public detection tools on actual viral videos that went around social media - including deepfakes of Obama, Biden, Trump, and Bollywood celebrities. This real-world testing reveals problems that lab studies missed.</p>
          </div>
        </div>
        
        <div class="faq-item">
          <button class="faq-question" onclick="toggleFAQ(this)">
            <span>What are the limitations of this work?</span>
            <span class="faq-toggle">+</span>
          </button>
          <div class="faq-answer">
            <p>Our sample size was limited to 20 high-profile viral videos, which may not represent all types of deepfakes. Ground truth was established through public debunking reports rather than direct access to generation tools. Results reflect a snapshot in time since detection models evolve rapidly. We also focused on English-language and primarily Western/Indian content.</p>
          </div>
        </div>
        
        <div class="faq-item">
          <button class="faq-question" onclick="toggleFAQ(this)">
            <span>How can I reproduce these results?</span>
            <span class="faq-toggle">+</span>
          </button>
          <div class="faq-answer">
            <p>We provide complete video lists, platform URLs (Deepware.ai and DeepFake-O-Meter), and our evaluation methodology in the paper. Since these are web-based tools, anyone can test the same videos we used. However, results may vary over time as the platforms update their models.</p>
          </div>
        </div>

        <div class="faq-item">
          <button class="faq-question" onclick="toggleFAQ(this)">
            <span>What's next for this research?</span>
            <span class="faq-toggle">+</span>
          </button>
          <div class="faq-answer">
            <p>We plan to expand testing to more diverse content (different languages, cultures, generation methods), develop better consensus algorithms that combine multiple detectors, and work with platform developers to improve transparency about how their tools work. We also want to create standardized benchmarks for real-world deepfake evaluation.</p>
          </div>
        </div>

        <div class="faq-item">
          <button class="faq-question" onclick="toggleFAQ(this)">
            <span>Should I trust online deepfake detectors?</span>
            <span class="faq-toggle">+</span>
          </button>
          <div class="faq-answer">
            <p>Use them as helpful hints, not definitive answers. Our research shows they miss many real deepfakes (low sensitivity) but rarely call real videos fake (high specificity). For important decisions - like news verification or legal evidence - always combine automated tools with human expert review and multiple sources of verification.</p>
          </div>
        </div>
      </div>
    </div>

    <!-- Related Work Section -->
  <div class="content-section" id="related-work">
      <h2>🔗 Related Work</h2>
      <div class="related-work-content">
        <p>Our research builds upon extensive prior work in deepfake detection while addressing a critical gap: most studies evaluate models on controlled laboratory datasets rather than real-world viral content. This work bridges that gap by testing public tools on authentic viral media.</p>
        <ul>
          <li><strong>DSP-FWA (2019) & FTCN (2021)</strong> - Early detection algorithms that showed promise on controlled datasets but limited real-world performance</li>
          <li><strong>Deepfake-Eval-2024</strong> - Recent benchmark showing 50% AUC drops when models face in-the-wild content, confirming our hypothesis</li>
          <li><strong>Tolosana et al. (2020)</strong> - Comprehensive survey of face manipulation techniques that informed our understanding of deepfake generation methods</li>
          <li><strong>UB Media Forensics Lab</strong> - Developers of DeepFake-O-Meter platform that enabled our multi-model evaluation approach</li>
        </ul>
        <p><strong>Novel Contribution:</strong> Unlike previous studies that focus on algorithmic improvements, we provide the first systematic evaluation of publicly accessible detection tools on viral real-world content, revealing critical limitations for practical deployment.</p>
      </div>
    </div>

    <!-- ===== REPLICATION & RESOURCES ===== -->



  <!-- Removed duplicate Infographic Section -->

    <!-- Technical Resources Section -->
  <div class="content-section" id="supplementary">
      <h2>� Technical Resources</h2>
      <div class="supplementary-grid">
        <div class="supplementary-card">
          <div class="supplementary-icon">📈</div>
          <h3>Extended Results</h3>
          <p>Additional experiments and detailed analysis not included in the main paper.</p>
          <a href="#" class="supplementary-link">View Results →</a>
        </div>
        
        <div class="supplementary-card">
          <div class="supplementary-icon">🧪</div>
          <h3>Experiment Logs</h3>
          <p>Detailed logs from all experiments including failed attempts and iterations.</p>
          <a href="#" class="supplementary-link">Download Logs →</a>
        </div>
        
        <div class="supplementary-card">
          <div class="supplementary-icon">📊</div>
          <h3>Raw Data</h3>
          <p>Complete dataset and raw experimental data for further analysis.</p>
          <a href="#" class="supplementary-link">Access Data →</a>
        </div>
        
        <div class="supplementary-card">
          <div class="supplementary-icon">🎥</div>
          <h3>Presentation Slides</h3>
          <p>Slides from conference presentations and lab meetings.</p>
          <a href="#" class="supplementary-link">View Slides →</a>
        </div>
        
        <div class="supplementary-card">
          <div class="supplementary-icon">📝</div>
          <h3>Technical Appendix</h3>
          <p>Detailed mathematical derivations and additional technical details.</p>
          <a href="#" class="supplementary-link">Read More →</a>
        </div>
        
        <div class="supplementary-card">
          <div class="supplementary-icon">�</div>
          <h3>Related Work</h3>
          <p>Comprehensive literature review and related research links.</p>
          <a href="#" class="supplementary-link">Explore →</a>
        </div>
      </div>
    </div>

    <!-- Replicability Guide -->
  <div class="content-section" id="replicability">
      <h2>
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 8px;">
          <path d="M14.7 6.3a1 1 0 000 1.4l1.6 1.6a1 1 0 001.4 0l3.77-3.77a6 6 0 01-7.94 7.94l-6.91 6.91a2.12 2.12 0 01-3-3l6.91-6.91a6 6 0 017.94-7.94l-3.76 3.76z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
        </svg>
        Replicability Guide
      </h2>
      <div class="replicability-content">
        <div class="replicability-overview">
          <h3>
            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 6px;">
              <path d="M9 12l2 2 4-4" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
              <path d="M21 12c.552 0 1-.45 1-1s-.448-1-1-1-1 .45-1 1 .448 1 1 1zM3 12c.552 0 1-.45 1-1s-.448-1-1-1-1 .45-1 1 .448 1 1 1zM12 21c.552 0 1-.45 1-1s-.448-1-1-1-1 .45-1 1 .448 1 1 1zM12 3c.552 0 1-.45 1-1s-.448-1-1-1-1 .45-1 1 .448 1 1 1z" stroke="currentColor" stroke-width="2"/>
            </svg>
            Quick Start
          </h3>
          <p>To reproduce our benchmarking study, researchers need access to the same detection platforms and video samples we used. Since our study evaluates publicly available tools on viral content, the main requirements are platform access and careful documentation of scan parameters.</p>
        </div>
        
        <div class="replicability-steps">
          <h3>
            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 6px;">
              <path d="M14.7 6.3a1 1 0 000 1.4l1.6 1.6a1 1 0 001.4 0l3.77-3.77a6 6 0 01-7.94 7.94l-6.91 6.91a2.12 2.12 0 01-3-3l6.91-6.91a6 6 0 017.94-7.94l-3.76 3.76z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
            </svg>
            Step-by-Step Instructions
          </h3>
          <div class="step-item">
            <div class="step-number">1</div>
            <div class="step-content">
              <h4>Platform Access</h4>
              <p>Obtain access to detection platforms:</p>
              <ul>
                <li><strong>Deepware AI Scanner:</strong> https://deepware.ai (free beta access)</li>
                <li><strong>DeepFake-O-Meter:</strong> https://zinc.cse.buffalo.edu/ubmdfl/deep-o-meter/landing_page (research access)</li>
              </ul>
            </div>
          </div>
          
          <div class="step-item">
            <div class="step-number">2</div>
            <div class="step-content">
              <h4>Video Sample Collection & Dataset</h4>
              <p>Our study used 20 carefully selected viral videos (10 deepfakes + 10 authentic) featuring prominent public figures. All samples are available for research replication:</p>
              
              <div class="bulk-download-section">
                <h5>
                  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="margin-right: 8px;">
                    <path d="M4 17v2a2 2 0 002 2h12a2 2 0 002-2v-2M7 11l5 5 5-5m-5 5V4" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                  </svg>
                  Complete Dataset Download
                </h5>
                <p style="margin: 0 0 15px 0; color: #6c757d; font-size: 0.95em;">Download all 20 video samples (deepfakes + authentic) in a single compressed archive</p>
                <div class="bulk-download-buttons" style="display: flex; justify-content: center; gap: 15px; flex-wrap: wrap;">
                  <a class="download-all-btn" href="https://zenodo.org/records/17208948/files/Fake%20Video%20Test.zip?download=1" style="background: #dc3545; color: white; border: none; padding: 12px 24px; border-radius: 6px; cursor: pointer; font-size: 1em; font-weight: 500; display: flex; align-items: center; gap: 8px;" download>
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                      <path d="M21 15v4a2 2 0 01-2 2H5a2 2 0 01-2-2v-4m4-5l5 5 5-5m-5 5V3" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                    </svg>
                    Download All Deepfakes (10 videos)
                  </a>
                  <a class="download-all-btn" href="https://zenodo.org/records/17208948/files/Real%20Video%20Test.zip?download=1" style="background: #28a745; color: white; border: none; padding: 12px 24px; border-radius: 6px; cursor: pointer; font-size: 1em; font-weight: 500; display: flex; align-items: center; gap: 8px;" download>
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                      <path d="M21 15v4a2 2 0 01-2 2H5a2 2 0 01-2-2v-4m4-5l5 5 5-5m-5 5V3" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                    </svg>
                    Download All Authentic (10 videos)
                  </a>
                  <a class="download-all-btn" href="https://zenodo.org/records/17208948/files/Dataset.zip?download=1" style="background: #6f42c1; color: white; border: none; padding: 12px 24px; border-radius: 6px; cursor: pointer; font-size: 1em; font-weight: 500; display: flex; align-items: center; gap: 8px;" download>
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                      <path d="M21 15v4a2 2 0 01-2 2H5a2 2 0 01-2-2v-4m4-5l5 5 5-5m-5 5V3" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                    </svg>
                    Download Complete Dataset (20 videos)
                  </a>
                   <a class="download-all-btn" href="https://zenodo.org/records/17208948/files/Benchmarking%20and%20Cross-Platform%20Evaluation%20of%20Public%20Deepfake%20Detection%20Models%20on%20Viral%20Real-World%20Media%20Raw%20Data%20Results.pdf?download=1" style="background: #6f42c1; color: white; border: none; padding: 12px 24px; border-radius: 6px; cursor: pointer; font-size: 1em; font-weight: 500; display: flex; align-items: center; gap: 8px;" download>
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                      <path d="M21 15v4a2 2 0 01-2 2H5a2 2 0 01-2-2v-4m4-5l5 5 5-5m-5 5V3" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                    </svg>
                    Download Test Results
                  </a>
                </div>
                <div class="download-info">
                  <small style="color: #495057;">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="margin-right: 4px;">
                      <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"/>
                      <path d="M12 16v-4m0-4h.01" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                    </svg>
                    Archive sizes: Deepfakes (~180MB) | Authentic (~195MB) | Complete Dataset (~375MB)
                  </small>
                </div>
              </div>
              
              <div class="video-samples-grid" style="display: grid; grid-template-columns: repeat(auto-fit, minmax(350px, 1fr)); gap: 20px; margin: 20px 0;">
                
                <!-- Deepfake Samples (exact match) -->
                <div class="sample-category">
                  <h5 style="color: #e74c3c; margin-bottom: 15px;">
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="margin-right: 6px;">
                      <path d="M12 9v4m0 4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z" stroke="currentColor" stroke-width="2"/>
                    </svg>
                    Deepfake Samples (10)
                  </h5>
                  <div class="video-sample-item"><h6>Viral Deepfake Videos Thrive Of Aamir Khan Endorsing Political Parties – Business today</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/Amir%20Khan.mp4?download=1" style="background: #007bff; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>Viral Deepfake Videos Thrive Of Ranveer Singh Endorsing Political Parties – Business today</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/Ranveer%20Singh.mp4?download=1" style="background: #007bff; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>Amit Shah Fake Video: Debunking the Fake Video of Amit Shah On Reservations – The Indian Express</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/Amit%20Shah.mp4?download=1" style="background: #007bff; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>AI Deepfake Video Of Actress Rashmika Mandanna Going Viral – Business Today</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/Rashmika.mp4?download=1" style="background: #007bff; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>Anderson Cooper, 4K Original/(Deep) Fake Example - LipSynthesis</h6><a class="download-btn" href="dataset/Fake%20Video%20Test/Anderson%20Cooper.mp4" style="background: #007bff; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>Fake Obama created using AI video tool - BBC News</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/Obama.mp4?download=1" style="background: #007bff; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>This is not Morgan Freeman - A Deepfake Singularity</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/MorganFreeman.mp4?download=1" style="background: #007bff; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>President Joe Biden's Magical Pistachio Story (Deepfake AI)</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/Joe.mp4?download=1" style="background: #007bff; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>2024 Deepfake Example in 4k - ORIGINAL/DEEPFAKE - Bill Gates</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/Bill%20Gates.mp4?download=1" style="background: #007bff; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>Trump 4k Deepfake example – LipSynthesis</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/Trump.mp4?download=1" style="background: #007bff; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                </div>
                
                <!-- Authentic Samples -->
                <!-- Authentic Samples (exact match) -->
                <div class="sample-category">
                  <h5 style="color: #28a745; margin-bottom: 15px;">
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="margin-right: 6px;">
                      <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z" stroke="currentColor" stroke-width="2"/>
                    </svg>
                    Authentic Samples (10)
                  </h5>
                  <div class="video-sample-item"><h6>Aamir Khan-Reena की लव स्टोरी कैसे शुरू हुई, घरवालों ने क्या हंगामा किया, छुपकर शादी क्यों करनी पड़ी.mp4</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/Aamir%20Khan-Reena%20%E0%A4%95%E0%A5%80%20%E0%A4%B2%E0%A4%B5%20%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A5%8B%E0%A4%B0%E0%A5%80%20%E0%A4%95%E0%A5%88%E0%A4%B8%E0%A5%87%20%E0%A4%B6%E0%A5%81%E0%A4%B0%E0%A5%82%20%E0%A4%B9%E0%A5%81%E0%A4%88,%20%E0%A4%98%E0%A4%B0%E0%A4%B5%E0%A4%BE%E0%A4%B2%E0%A5%8B%E0%A4%82%20%E0%A4%A8%E0%A5%87%20%E0%A4%95%E0%A5%8D%E0%A4%AF%E0%A4%BE%20%E0%A4%B9%E0%A4%82%E0%A4%97%E0%A4%BE%E0%A4%AE%E0%A4%BE%20%E0%A4%95%E0%A4%BF%E0%A4%AF%E0%A4%BE,%20%E0%A4%9B%E0%A5%81%E0%A4%AA%E0%A4%95%E0%A4%B0%20%E0%A4%B6%E0%A4%BE%E0%A4%A6%E0%A5%80%20%E0%A4%95%E0%A5%8D%E0%A4%AF%E0%A5%8B%E0%A4%82%20%E0%A4%95%E0%A4%B0%E0%A4%A8%E0%A5%80%20%E0%A4%AA%E0%A5%9C%E0%A5%80.mp4?download=1" style="background: #28a745; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>Anderson Cooper’s tribute to his friend Anthony Bourdain.mp4</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/Anderson%20Cooper%E2%80%99s%20tribute%20to%20his%20friend%20Anthony%20Bourdain.mp4?download=1" style="background: #28a745; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>Highlights from Obama's farewell address.mp4</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/Highlights%20from%20Obama's%20farewell%20address.mp4?download=1" style="background: #28a745; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>HM Amit Shah’s Fiery Remark in Parliament_ ‘Hindu Terrorist Nahi Ho Sakta’ _ Amit Shah _ Rajya Sabha.mp4</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/HM%20Amit%20Shah%E2%80%99s%20Fiery%20Remark%20in%20Parliament_%20%E2%80%98Hindu%20Terrorist%20Nahi%20Ho%20Sakta%E2%80%99%20_%20Amit%20Shah%20_%20Rajya%20Sabha.mp4?download=1" style="background: #28a745; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>Morgan Freeman Re-Enacts The Shawshank Redemption _ The Graham Norton Show.mp4</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/Morgan%20Freeman%20Re-Enacts%20The%20Shawshank%20Redemption%20_%20The%20Graham%20Norton%20Show.mp4?download=1" style="background: #28a745; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>President Joe Biden Takes the Oath of Office _ Biden-Harris Inauguration 2021.mp4</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/President%20Joe%20Biden%20Takes%20the%20Oath%20of%20Office%20_%20Biden-Harris%20Inauguration%202021.mp4?download=1" style="background: #28a745; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>President Trump's Inaugural Address.mp4</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/President%20Trump's%20Inaugural%20Address.mp4?download=1" style="background: #28a745; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>Ranveer Singh On Playing Khilji In Padmaavat _ India Today Exclusive Interview.mp4</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/Ranveer%20Singh%20On%20Playing%20Khilji%20In%20Padmaavat%20_%20India%20Today%20Exclusive%20Interview.mp4?download=1" style="background: #28a745; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>Rashmika Mandanna Interview with Anupama Chopra _ Mission Majnu _ Goodbye _ Film Companion.mp4</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/Rashmika%20Mandanna%20Interview%20with%20Anupama%20Chopra%20_%20Mission%20Majnu%20_%20Goodbye%20_%20Film%20Companion.mp4?download=1" style="background: #28a745; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                  <div class="video-sample-item"><h6>The next outbreak_ We’re not ready _ Bill Gates _ TED.mp4</h6><a class="download-btn" href="https://zenodo.org/records/17208948/files/The%20next%20outbreak_%20We%E2%80%99re%20not%20ready%20_%20Bill%20Gates%20_%20TED.mp4?download=1" style="background: #28a745; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; font-size: 0.9em;" download>Download Sample</a></div>
                </div>
              </div>
              
              <div class="dataset-info">
                <h6>
                  <svg width="16" height="16" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="margin-right: 6px;">
                    <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2"/>
                    <path d="M12 6v6l4 2" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                  </svg>
                  Dataset Technical Specifications
                </h6>
                <ul style="margin: 0; color: #1976d2;">
                  <li><strong>File Format:</strong> MP4 containers using H.264 encoding</li>
                  <li><strong>File Sizes:</strong> 5.7 MB to 34.4 MB</li>
                  <li><strong>Durations:</strong> 48 to 242 seconds</li>
                  <li><strong>Resolutions:</strong> 480×360 to 3840×2160 pixels</li>
                  <li><strong>Processing:</strong> No manipulation or normalization applied</li>
                  <li><strong>Verification:</strong> Ground truth established via public debunking reports and media documentation</li>
                </ul>
              </div>
            </div>
          </div>
          
          <div class="step-item">
            <div class="step-number">3</div>
            <div class="step-content">
              <h4>Data Collection Protocol</h4>
              <p>For each video, systematically record:</p>
              <ul>
                <li>Ground-truth label (deepfake vs authentic)</li>
                <li>Platform ensemble scores and categorical labels</li>
                <li>Per-component/model scores when available</li>
                <li>Scan timestamps and platform version info</li>
                <li>Any analyst notes or special conditions</li>
              </ul>
            </div>
          </div>
          
          <div class="step-item">
            <div class="step-number">4</div>
            <div class="step-content">
              <h4>Analysis & Interpretation</h4>
              <p>Apply our evaluation framework:</p>
              <ul>
                <li>Compute confusion matrices for different binary mappings</li>
                <li>Calculate sensitivity, specificity, accuracy, precision, F1 scores</li>
                <li>Analyze cross-platform agreement and per-model variance</li>
                <li>Document threshold choices and operational implications</li>
              </ul>
            </div>
          </div>
        </div>
        
        <div class="replicability-resources">
          <h3>📦 Resources</h3>
          <div class="resource-links">
            <a href="#" class="resource-link">
              <span class="resource-icon">💻</span>
              <span>Code Repository</span>
            </a>
            <a href="#" class="resource-link">
              <span class="resource-icon">📊</span>
              <span>Dataset</span>
            </a>
            <a href="#" class="resource-link">
              <span class="resource-icon">�</span>
              <span>Requirements.txt</span>
            </a>
            <a href="#" class="resource-link">
              <span class="resource-icon">🐳</span>
              <span>Docker Image</span>
            </a>
          </div>
        </div>
      </div>
    </div>



    <!-- Step 9 Start: Add your paper acknowledgement -->

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    -->

  <div class="content-section" id="acknowledgement">
      <h2>
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 8px;">
          <path d="M20.84 4.61a5.5 5.5 0 00-7.78 0L12 5.67l-1.06-1.06a5.5 5.5 0 00-7.78 7.78l1.06 1.06L12 21.23l7.78-7.78 1.06-1.06a5.5 5.5 0 000-7.78z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
        </svg>
        Acknowledgements
      </h2>
      <div class="acknowledgements-content">
      <p>We thank Mrs. Sirisha Vadigineni (Narayana E-Techno and Olympiad School, Whitefield, Bengaluru) and Mrs. Ramya Shujith (Glentree Academy, Whitefield, Bengaluru) for their guidance and support during this research. 
<br>
        This work utilized the Deepware Scanner <a href = "https://deepware.ai">https://deepware.ai</a> and the DeepFake-o-meter platform <a href = "https://zinc.cse.buffalo.edu/ubmdfl/deep-o-meter/landing_page">https://zinc.cse.buffalo.edu/ubmdfl/deep-o-meter/landing_page</a>, which provided accessible and effective tools for detecting synthetic media. I acknowledge the contributions of the teams behind these tools, including the UB Media Forensics Lab, supported by the University at Buffalo and the National Science Foundation under Grant SaTC-2153112.
</p>
      </div>
    </div>

    <!-- Contact & Collaboration Section -->
  <div class="content-section" id="contact">
      <h2>
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 8px;">
          <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
          <path d="M22 6l-10 7L2 6" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
        </svg>
        Contact & Collaborate
      </h2>
      <div class="contact-content">
        <div class="contact-intro">
          <p>Interested in our deepfake detection research? Have questions about our methodology or want to collaborate on misinformation detection? We'd love to hear from you!</p>
        </div>
        
        <div class="contact-methods">
          <div class="contact-card">
            <div class="contact-icon">
              <svg width="32" height="32" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                <path d="M22 6l-10 7L2 6" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
              </svg>
            </div>
            <h3>Primary Contact</h3>
            <p>For research inquiries and collaboration</p>
            <p><strong>Tuhin Sarkar</strong><br>Student Researcher<br>Glentree Academy, Bengaluru</p>
          </div>
          
        
          
          <div class="contact-card">
            <div class="contact-icon">
              <svg width="32" height="32" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                <path d="M3 21h18M3 7v1a3 3 0 003 3h12a3 3 0 003-3V7M3 7l9-4 9 4M8 21V10.5M16 21V10.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
              </svg>
            </div>
            <h3>Institution</h3>
            <p>High school research program</p>
            <p><strong>Glentree Academy</strong><br>Whitefield, Bengaluru<br>Karnataka, India</p>
          </div>
          
          <div class="contact-card">
            <div class="contact-icon">
              <svg width="32" height="32" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                <path d="M9.585 2.068a.5.5 0 01.226.58L8.677 6.24H9a.5.5 0 01.496.562l-.578 8.96A.5.5 0 018.422 16H3.578a.5.5 0 01-.496-.238L1.65 12.825a.5.5 0 01.033-.577L9.585 2.068z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                <path d="M16.5 6a4.5 4.5 0 11-9 0 4.5 4.5 0 019 0z" stroke="currentColor" stroke-width="2"/>
                <path d="M15 9.5a1.5 1.5 0 11-3 0 1.5 1.5 0 013 0z" stroke="currentColor" stroke-width="2"/>
              </svg>
            </div>
            <h3>Research Area</h3>
            <p>AI Ethics & Media Forensics</p>
            <p>Deepfake Detection<br>Misinformation Analysis</p>
          </div>
        </div>
        
        <div class="collaboration-interests">
          <h3>
            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline-block; margin-right: 6px;">
              <path d="M17 21v-2a4 4 0 00-4-4H5a4 4 0 00-4 4v2" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
              <circle cx="9" cy="7" r="4" stroke="currentColor" stroke-width="2"/>
              <path d="M23 21v-2a4 4 0 00-3-3.87m-4-12a4 4 0 010 7.75" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
            </svg>
            Open to Collaboration On:
          </h3>
          <div class="interests-tags">
            <span class="interest-tag">Deepfake Detection</span>
            <span class="interest-tag">Media Forensics</span>
            <span class="interest-tag">AI Ethics</span>
            <span class="interest-tag">Cross-platform Analysis</span>
            <span class="interest-tag">Social Media Research</span>
            <span class="interest-tag">Misinformation Studies</span>
          </div>
        </div>
      </div>
    </div>
  </div>
    <!-- Step 9 End: Add your paper acknowledgement -->

    <footer class="footer">
      <div class="footer-content">
        <div class="footer-inner">
          <div class="footer-main">
            <div class="footer-branding">
              <h3 class="footer-title">Benchmarking and Cross-Platform Evaluation of Public Deepfake Detection Models on Viral Real-World Media</h3>
              <p class="footer-subtitle">This research systematically evaluates public deepfake detection tools on real viral videos, revealing strengths, weaknesses, and inconsistencies across platforms and models. Our findings highlight the need for caution and human oversight when relying on automated detection in real-world scenarios.</p>
            </div>
            
            <div class="footer-links">
              <div class="footer-section">
                <h4>Research</h4>
                <a href="#tldr">TL;DR</a>
                <a href="#impact">Impact</a>
                <a href="#infographic">Infographic</a>
                <a href="#introduction">Introduction</a>
                <a href="#methodology">Methodology</a>
                <a href="#results">Results</a>
                <a href="#conclusion">Conclusion</a>
                <a href="#limitations">Limitations</a>
                <a href="#faq">FAQ</a>
                <a href="#related-work">Related Work</a>
              </div>
              
              <div class="footer-section">
                <h4>Resources</h4>
                <a href="#supplementary">Supplementary</a>
                <a href="#replicability">Replicability</a>
              </div>
              
              <div class="footer-section">
                <h4>Connect</h4>
                <a href="#contact">Contact</a>
                <a href="#acknowledgement">Acknowledgement</a>
              </div>
            </div>
          </div>
          
          <div class="footer-divider"></div>
          
          <div class="footer-bottom">
            <div class="footer-credits">
              <p>© 2024 Tuhin Sarkar. All rights reserved.</p>
        <p><a href = "https://creativecommons.org/licenses/by/4.0/">Attribution 4.0 International CC BY 4.0
</a></p>
            </div>
            
            <div class="footer-stats">
              <img src="https://profile-counter.glitch.me/indragithubpagetemplate/count.svg" alt="Profile Counter" class="footer-counter">
            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Do not edit below button -->
    <button class="scrollUpBtn" id="scrollUpBtn" onclick="scrollToTop()">
      ⬆
    </button>

    <script src="script.js"></script>
  </body>
</html>
